{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Autopilot Candidate Definition Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook was automatically generated by the AutoML job Six or Final model. This notebook allows you to customize the AutoGluon trials and execute the SageMaker Autopilot workflow.\n",
    "\n",
    "The dataset has 9 columns and the column named diabetes is used as the target column. This is being treated as a BinaryClassification problem. The dataset also has 2 classes. This notebook will build a BinaryClassification model that maximizes the \"F1\" quality metric of the trained models. The \"F1\" metric applies for binary classification with a positive and negative class. It mixes between precision and recall, and is recommended in cases where there are more negative examples compared to positive examples.\n",
    "\n",
    "As part of the AutoML job, the input dataset has been randomly split into two pieces, one for training and one for validation. Given an input dataset, Amazon SageMaker Autopilot runs a number of trials with different base models and metaparameter settings. This notebook helps you inspect and modify the metaparameters proposed by Amazon SageMaker Autopilot. You can interactively select one of the configurations proposed by Amazon SageMaker Autopilot, modify it and execute a processing job to train models as per the selected configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Contents\n",
    "2. Sagemaker Setup\n",
    "3. Downloading Generated Candidates\n",
    "4. SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration\n",
    "5. Candidate Trials\n",
    "6. Select Candidate to Train\n",
    "7. Update Selected Candidate\n",
    "8. Display Selected Candidate\n",
    "9. Executing the Candidate Trial\n",
    "10. Run Processing Job\n",
    "11. Model Deployment\n",
    "Deploying the Trained Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Setup\n",
    "Before you launch the SageMaker Autopilot jobs, we'll setup the environment for Amazon SageMaker\n",
    "\n",
    "1. Check environment & dependencies.\n",
    "2. Create a few helper objects/function to organize input/output data and SageMaker     sessions.\n",
    "3. Minimal Environment Requirements\n",
    "\n",
    "4. Jupyter: Tested on JupyterLab 1.0.6, jupyter_core 4.5.0 and IPython 6.4.0\n",
    "5. Kernel: conda_python3\n",
    "6. Dependencies required\n",
    "7. sagemaker-python-sdk>=2.40.0\n",
    "8. Use !pip install sagemaker==2.40.0 to download this dependency.\n",
    "9. Kernel may need to be restarted after download.\n",
    "10. Expected Execution Role/permission\n",
    "11. S3 access to the bucket that stores the notebook.\n",
    "12. Downloading Generated Modules\n",
    "13. Download the generated trial configurations and a SageMaker Autopilot helper module used by this notebook. Those artifacts will be downloaded to six-artifacts folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Generated Modules\n",
    "Download the generated trial configurations and a SageMaker Autopilot helper module used by this notebook. Those artifacts will be downloaded to six-artifacts folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p six-artifacts\n",
    "!aws s3 sync s3://sagemaker-studio-359522689357-fzxtb6a46av/six/sagemaker-automl-candidates/notebooks/sagemaker_automl_ensemble six-artifacts/sagemaker_automl_ensemble --only-show-errors\n",
    "!aws s3 sync s3://sagemaker-studio-359522689357-fzxtb6a46av/six/sagemaker-automl-candidates/notebooks/trial_configs six-artifacts/trial_configs --only-show-errors\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"six-artifacts\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration\n",
    "The following configuration has been derived from the SageMaker Autopilot job. These items configure where this notebook will look for generated candidates, and where input and output data is stored on Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_automl_ensemble import AutoMLLocalEnsembleRunConfig, uid\n",
    "\n",
    "# Where the existing AutoML job is stored\n",
    "BASE_AUTOML_JOB_NAME = 'six'\n",
    "BASE_AUTOML_JOB_CONFIG = {\n",
    "    'automl_job_name': BASE_AUTOML_JOB_NAME,\n",
    "    'automl_output_s3_base_path': 's3://sagemaker-studio-359522689357-fzxtb6a46av/six'\n",
    "}\n",
    "\n",
    "# Path conventions of the output data storage path from the local AutoML job run of this notebook\n",
    "LOCAL_AUTOML_JOB_NAME = 'six-notebook-run-{}'.format(uid())\n",
    "LOCAL_AUTOML_JOB_CONFIG = {\n",
    "    'local_automl_job_name': LOCAL_AUTOML_JOB_NAME,\n",
    "    'local_automl_job_output_s3_base_path': 's3://sagemaker-studio-359522689357-fzxtb6a46av/six/{}'.format(LOCAL_AUTOML_JOB_NAME),\n",
    "}\n",
    "\n",
    "AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG = AutoMLLocalEnsembleRunConfig(\n",
    "    test_artifacts_path = 'six-artifacts',\n",
    "    base_automl_job_config = BASE_AUTOML_JOB_CONFIG,\n",
    "    local_automl_job_config = LOCAL_AUTOML_JOB_CONFIG\n",
    ")\n",
    "\n",
    "AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Trials\n",
    "Select Candidate to Train\n",
    "The SageMaker Autopilot Job has analyzed the dataset and has generated a number of trial configurations with different metaparameter settings. You can select a trial configuration that you wish to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "trials_dropdown = AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.dropdown\n",
    "interact(AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.select_trial, trials_dropdown=trials_dropdown)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Selected Candidate\n",
    "By editing and saving the metaparameters.json file, you can update the metaparameters that will be used for training. (To edit the file use Right Click->Open With->Editor.)\n",
    "IF you wish to reselect another trial from the dropdown, make sure you close and reopen the metaparameters.json file tab, before editing.\n",
    "\n",
    "The following are the metaparameters that can be updated. You can update the metaparameters of your choice. The updated parameters will be passed to AutoGluon predictor for training. For a detailed description of the parameters, refer to the description of each arguments in AutoGluon predictor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available Knobs\n",
    "num_bag_sets: Number of repeats of kfold bagging to perform. Valid values: integer\n",
    "included_model_types: List of models to train. Valid values: any subset of following list: [\"XGB\", \"GBM\", \"CAT\", \"FASTAI\", \"NN_TORCH\", \"LR\", \"RF\", \"XT\"]\n",
    "\"XGB\" (XGBoost)\n",
    "\"GBM\" (LightGBM)\n",
    "\"CAT\" (CatBoost)\n",
    "\"FASTAI\" (neural network with FastAI backend)\n",
    "\"NN_TORCH\" ((neural network implemented in Pytorch)\n",
    "\"LR\" (linear regression)\n",
    "\"RF\" (random forest)\n",
    "\"XT\" (extremely randomized trees)\n",
    "presets: List of preset configurations for various arguments. ['best_quality', 'high_quality', 'good_quality', 'medium_quality', 'optimize_for_deployment', 'interpretable', 'ignore_text']\n",
    "It is recommended to only use one quality based preset in a given call to fit() as they alter many of the same arguments and are not compatible with each-other.\n",
    "auto_stack: Whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy. Valid values: boolean\n",
    "num_stack_levels: Number of stacking levels to use in stack ensemble. Valid values: integer\n",
    "refit_full: Whether to retrain all models on all of the data (training + validation) after the normal training procedure. Valid values: boolean\n",
    "set_best_to_refit_full: If True, AutoGluon will change the default model that Predictor uses for prediction when model is not specified to the refit_full version of the model that exhibited the highest validation score. Only valid if refit_full is set. Valid values: boolean\n",
    "save_bag_folds: Whether bagged models will save their fold models. Valid values: boolean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Candidate Metaparameters\n",
    "You have selected the following metaparameters for your trial. (please run the cell below to load and display your selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.display_candidate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing the Candidate Trial\n",
    "Run Processing Job\n",
    "Now you are ready to create processing job with the updated trial configuration.\n",
    "\n",
    "Prepare Processor and Processing Job Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import Processor\n",
    "\n",
    "processor_args = AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.prepare_processor_args()\n",
    "processor = Processor(**processor_args)\n",
    "\n",
    "processing_inputs = AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.prepare_processing_inputs()\n",
    "processing_outputs = AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.prepare_processing_outputs()\n",
    "processing_job_name = AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.local_automl_job_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Processing Job for the Selected Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(\n",
    "Markdown(f\"Creating Processing Job {processing_job_name}, please track the progress from [here](https://{AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.region}.console.aws.amazon.com/sagemaker/home?region={AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.region}#/processing-jobs/{processing_job_name}).\"))\n",
    "\n",
    "processor.run(\n",
    "    job_name = processing_job_name,\n",
    "    inputs = processing_inputs,\n",
    "    outputs = processing_outputs,\n",
    "    logs = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "Now, you can deploy the trained model from the processing job. After the deployment completes, you will get an endpoint that's ready to serve online inference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💡 Available Knobs\n",
    "You can customize the initial instance count and instance type used to deploy this model.\n",
    "Endpoint name can be changed to avoid conflict with existing endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model_args = AUTOML_LOCAL_ENSEMBLE_RUN_CONFIG.prepare_model_args()\n",
    "model = Model(**model_args)\n",
    "\n",
    "model.deploy(initial_instance_count=2,\n",
    "             instance_type='ml.m5.12xlarge',\n",
    "             endpoint_name=\"AutoML-{}\".format(processing_job_name),\n",
    "             wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
